{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b76347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import IMDB\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_sparse import SparseTensor\n",
    "import torch\n",
    "from torch.nn import Embedding,Sequential, Linear, ReLU, BatchNorm1d,Dropout,LeakyReLU,CrossEntropyLoss\n",
    "from torch import nn\n",
    "from torch.optim import Adam, SGD\n",
    "import copy\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ecfe3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = IMDB('./')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ebb0c",
   "metadata": {},
   "source": [
    "Target is Movie level predictions, as one of three classes (Action, Comedy, and Drama)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63860a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(data['movie'].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d343af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.rand(4278)<0.8\n",
    "train_idx = torch.where(idx)[0]\n",
    "val_idx = torch.where(~idx)[0]\n",
    "\n",
    "y = data['movie'].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbc19c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[4278, 3066],\n",
       "    y=[4278],\n",
       "    train_mask=[4278],\n",
       "    val_mask=[4278],\n",
       "    test_mask=[4278]\n",
       "  },\n",
       "  \u001b[1mdirector\u001b[0m={ x=[2081, 3066] },\n",
       "  \u001b[1mactor\u001b[0m={ x=[5257, 3066] },\n",
       "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 4278] },\n",
       "  \u001b[1m(movie, to, actor)\u001b[0m={ edge_index=[2, 12828] },\n",
       "  \u001b[1m(director, to, movie)\u001b[0m={ edge_index=[2, 4278] },\n",
       "  \u001b[1m(actor, to, movie)\u001b[0m={ edge_index=[2, 12828] }\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bee631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4069e738",
   "metadata": {},
   "source": [
    "### model-1, concat type features\n",
    "Concat node and edge together. Only possible when dimensions are the same across types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd26c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_data = data.to_homogeneous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02791c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 34212], x=[11616, 3066], node_type=[11616], edge_type=[34212])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b84ae1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(homo_data.x[:4278]==data['movie'].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f50804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de27a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 8\n",
    "in_d = 3066\n",
    "d = 128\n",
    "d_type = 256\n",
    "out_d = 3\n",
    "node_embed_types = 3\n",
    "edge_embed_types = 4\n",
    "heads = 4\n",
    "dropout = 0.1\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffd7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6ec8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_block(torch.nn.Module):\n",
    "    def __init__(self,d,d_type,heads,dropout,multiple_factor=2):\n",
    "        super(GAT_block, self).__init__()   \n",
    "        self.v_update =  Sequential(Dropout(dropout),\n",
    "                                    BatchNorm1d(d),\n",
    "                                    Linear(d,d*multiple_factor),\n",
    "                                    LeakyReLU(inplace=True),\n",
    "                                    Dropout(dropout),\n",
    "                                    BatchNorm1d(d*multiple_factor),\n",
    "                                    Linear(d*multiple_factor,d),\n",
    "                                    LeakyReLU(inplace=True))      \n",
    "        self.conv = GATv2Conv(d,d//heads,heads,edge_dim=d_type,dropout=dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x_new = self.conv(x, edge_index, edge_attr)\n",
    "        x_new = self.v_update(x_new)\n",
    "        return x+x_new\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'GAT_block'  \n",
    "\n",
    "class GNN1(torch.nn.Module):\n",
    "    def __init__(self,layers,d,d_type,out_d,node_embed_types,\n",
    "                 edge_embed_types,heads,dropout,multiple_factor=2):\n",
    "        super(GNN1, self).__init__()\n",
    "        self.node_type_embed = Embedding(node_embed_types, d_type)\n",
    "        self.edge_type_embed = Embedding(edge_embed_types, d_type)\n",
    "        self.input_linear = Sequential(BatchNorm1d(in_d+d_type),\n",
    "                                        Linear(in_d+d_type,d*2),\n",
    "                                        LeakyReLU(inplace=True),\n",
    "                                        BatchNorm1d(d*2),\n",
    "                                        Linear(d*2,d),\n",
    "                                        LeakyReLU(inplace=True))\n",
    "        self.conv = nn.ModuleList([GAT_block(d,d_type,heads,dropout,multiple_factor) for _ in range(layers)])\n",
    "        self.out_linear = Sequential(BatchNorm1d(d),\n",
    "                                        Linear(d,d*2),\n",
    "                                        LeakyReLU(inplace=True),\n",
    "                                        BatchNorm1d(d*2),\n",
    "                                        Linear(d*2,out_d))\n",
    "        self.loss = CrossEntropyLoss()\n",
    "        self.register_buffer('train_idx', train_idx)\n",
    "        self.register_buffer('val_idx',val_idx)\n",
    "        self.register_buffer('train_y', y[train_idx])\n",
    "        self.register_buffer('val_y', y[val_idx])\n",
    "        \n",
    "    def forward(self, x, edge_index, node_type,edge_type,IsTrain=False):\n",
    "        node_embed = self.node_type_embed(node_type)\n",
    "        edge_embed = self.edge_type_embed(edge_type)\n",
    "        x = torch.cat([x,node_embed],1)\n",
    "        x = self.input_linear(x)\n",
    "        for conv in self.conv:\n",
    "            x = conv(x, edge_index, edge_embed)\n",
    "        x = x[:4278] # take only the movie nodes\n",
    "        x = self.out_linear(x)\n",
    "        if IsTrain:\n",
    "            train_loss = self.loss(x[self.train_idx],self.train_y)\n",
    "            yhat = x[self.val_idx].detach().cpu().numpy().argmax(1)\n",
    "            val_loss = f1_score(y.numpy()[val_idx],yhat,average='micro')\n",
    "            return train_loss,val_loss\n",
    "        else:\n",
    "            return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9a2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN1(layers,d,d_type,out_d,node_embed_types,\n",
    "                 edge_embed_types,heads,dropout)\n",
    "model = model.to('cuda')\n",
    "homo_data = homo_data.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6380c9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train:1.1813830137252808, F1-val:0.35878787878787877\n",
      "epoch:1, train:1.06571364402771, F1-val:0.4109090909090909\n",
      "epoch:2, train:0.9005047678947449, F1-val:0.4484848484848485\n",
      "epoch:3, train:0.7641838192939758, F1-val:0.5272727272727272\n",
      "epoch:4, train:0.5908159017562866, F1-val:0.5915151515151515\n",
      "epoch:5, train:0.44413045048713684, F1-val:0.64\n",
      "epoch:6, train:0.3197781443595886, F1-val:0.6472727272727272\n",
      "epoch:7, train:0.23818936944007874, F1-val:0.6787878787878788\n",
      "epoch:8, train:0.16274069249629974, F1-val:0.6836363636363636\n",
      "epoch:9, train:0.11465346068143845, F1-val:0.6715151515151515\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "opt = Adam(model.parameters())\n",
    "increase_count = 1\n",
    "lossBest = -1\n",
    "count = 0\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss,val_loss = model(homo_data.x,homo_data.edge_index,homo_data.node_type,homo_data.edge_type,True)\n",
    "    print(\"epoch:{}, train:{}, F1-val:{}\".format(epoch,train_loss,val_loss))\n",
    "    if val_loss>lossBest:\n",
    "        lossBest = val_loss\n",
    "        bestWeight = copy.deepcopy(model.state_dict())\n",
    "        count = 0\n",
    "    else:\n",
    "        count += 1\n",
    "        if count > increase_count:\n",
    "            model.load_state_dict(bestWeight)\n",
    "            break\n",
    "    train_loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6646c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'micro:0.39151515151515154, macro:0.1988953866146849'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = model(homo_data.x,homo_data.edge_index,homo_data.node_type,homo_data.edge_type)\n",
    "yhat = yhat.detach().cpu().numpy().argmax(1)\n",
    "\n",
    "'micro:{}, macro:{}'.format(f1_score(y.numpy()[val_idx],yhat[val_idx],average='micro'),\n",
    "                            f1_score(y.numpy()[val_idx],yhat[val_idx],average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e00275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92878ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2c86e38",
   "metadata": {},
   "source": [
    "### Model-2\n",
    "Separate msg passing for each edge type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a65d7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameter\n",
    "layers=5\n",
    "d=128\n",
    "in_d=3066\n",
    "out_d=3\n",
    "dropout=0.1\n",
    "multiple_factor=2\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29da1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bipartite_msg(torch.nn.Module):\n",
    "    def __init__(self,d,dropout,multiple_factor):\n",
    "        super(bipartite_msg, self).__init__()   \n",
    "        self.in_linear = Linear(d,d)\n",
    "        self.out_linear = Sequential(Dropout(dropout),\n",
    "                                    BatchNorm1d(2*d),\n",
    "                                    Linear(2*d,multiple_factor*d),\n",
    "                                    LeakyReLU(inplace=True),\n",
    "                                    Dropout(dropout),\n",
    "                                    BatchNorm1d(multiple_factor*d),\n",
    "                                    Linear(multiple_factor*d,d),\n",
    "                                    LeakyReLU(inplace=True))   \n",
    "    \n",
    "    def forward(self, M, N, adj_m2n):\n",
    "        # message from M to N\n",
    "        # adj_m2n is SparseTensor of shape (n,m)\n",
    "        M = self.in_linear(M)\n",
    "        M2N = adj_m2n.matmul(M)\n",
    "        N_new = self.out_linear(torch.concat([N,M2N],1))\n",
    "        return N + N_new\n",
    "\n",
    "class bipartite_block(torch.nn.Module):\n",
    "    def __init__(self,d,dropout,multiple_factor):\n",
    "        super(bipartite_block, self).__init__()   \n",
    "        self.m2a = bipartite_msg(d,dropout,multiple_factor)\n",
    "        self.m2d = bipartite_msg(d,dropout,multiple_factor)\n",
    "        self.d2m = bipartite_msg(d,dropout,multiple_factor)\n",
    "        self.a2m = bipartite_msg(d,dropout,multiple_factor)\n",
    "    \n",
    "    def forward(self, M, A, D, adj_m2a, adj_m2d, adj_d2m, adj_a2m):\n",
    "        A = self.m2a(M,A,adj_m2a)\n",
    "        D = self.m2d(M,D,adj_m2d)\n",
    "        M = self.d2m(D,M,adj_d2m)\n",
    "        M = self.a2m(A,M,adj_a2m)\n",
    "        return M, A, D\n",
    "\n",
    "def MLP(in_d,out_d,multiple_factor):\n",
    "    return Sequential(BatchNorm1d(in_d),\n",
    "                        Linear(in_d,in_d*multiple_factor),\n",
    "                        LeakyReLU(inplace=True),\n",
    "                        BatchNorm1d(in_d*multiple_factor),\n",
    "                        Linear(in_d*multiple_factor,out_d),\n",
    "                        LeakyReLU(inplace=True))\n",
    "\n",
    "class GNN2(torch.nn.Module):\n",
    "    def __init__(self,layers,d,in_d,out_d,\n",
    "                 dropout,multiple_factor=2):\n",
    "        super(GNN2, self).__init__()\n",
    "\n",
    "        self.input_linear_A = MLP(in_d,d,multiple_factor)\n",
    "        self.input_linear_D = MLP(in_d,d,multiple_factor)\n",
    "        self.input_linear_M = MLP(in_d,d,multiple_factor)\n",
    "        self.conv = nn.ModuleList([bipartite_block(d,dropout,multiple_factor) for _ in range(layers)])\n",
    "        self.out_linear = MLP(d,out_d,multiple_factor)\n",
    "\n",
    "        self.loss = CrossEntropyLoss()\n",
    "        self.register_buffer('train_idx', train_idx)\n",
    "        self.register_buffer('val_idx',val_idx)\n",
    "        self.register_buffer('train_y', y[train_idx])\n",
    "        self.register_buffer('val_y', y[val_idx])\n",
    "        \n",
    "    def forward(self,M,A,D,adj_m2d,adj_m2a,adj_d2m,adj_a2m,IsTrain=False):\n",
    "        M = self.input_linear_M(M)\n",
    "        A = self.input_linear_A(A)\n",
    "        D = self.input_linear_D(D)\n",
    "        for conv in self.conv:\n",
    "            M, A, D = conv(M, A, D, adj_m2a, adj_m2d, adj_d2m, adj_a2m)\n",
    "        x = self.out_linear(M)\n",
    "        if IsTrain:\n",
    "            train_loss = self.loss(x[self.train_idx],self.train_y)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = self.loss(x[self.val_idx],self.val_y)\n",
    "            model.train()\n",
    "            return train_loss,val_loss\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e1c2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN2(layers,d,in_d,out_d,\n",
    "                 dropout,multiple_factor).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c244cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "M,A,D = data['movie'].x, data['actor'].x, data['director'].x\n",
    "\n",
    "m2d_idx = data['movie', 'to', 'director']['edge_index']\n",
    "m2a_idx = data['movie', 'to', 'actor']['edge_index']\n",
    "d2m_idx = data['director', 'to', 'movie']['edge_index']\n",
    "a2m_idx = data['actor', 'to', 'movie']['edge_index']\n",
    "\n",
    "adj_m2d = SparseTensor(row=m2d_idx[1],col=m2d_idx[0])\n",
    "adj_m2a = SparseTensor(row=m2a_idx[1],col=m2a_idx[0])\n",
    "adj_d2m = SparseTensor(row=d2m_idx[1],col=d2m_idx[0])\n",
    "adj_a2m = SparseTensor(row=a2m_idx[1],col=a2m_idx[0])\n",
    "\n",
    "M,A,D,adj_m2d,adj_m2a,adj_d2m,adj_a2m = [d.to('cuda') for d in [M,A,D,adj_m2d,adj_m2a,adj_d2m,adj_a2m]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8400133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train:1.124171257019043, val:1.1480956077575684\n",
      "epoch:1, train:0.9661462306976318, val:1.074554443359375\n",
      "epoch:2, train:0.7229357957839966, val:0.9850589632987976\n",
      "epoch:3, train:0.49748778343200684, val:0.9109905958175659\n",
      "epoch:4, train:0.33336037397384644, val:0.8700106739997864\n",
      "epoch:5, train:0.23222337663173676, val:0.8673908114433289\n",
      "epoch:6, train:0.1734304130077362, val:0.8900783658027649\n",
      "epoch:7, train:0.13900938630104065, val:0.8993144631385803\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "opt = Adam(model.parameters())\n",
    "increase_count = 1\n",
    "lossBest = 1e6\n",
    "count = 0\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss,val_loss = model(M,A,D,adj_m2d,adj_m2a,adj_d2m,adj_a2m,True)\n",
    "    print(\"epoch:{}, train:{}, val:{}\".format(epoch,train_loss,val_loss))\n",
    "    if val_loss<lossBest:\n",
    "        lossBest = val_loss\n",
    "        bestWeight = copy.deepcopy(model.state_dict())\n",
    "        count = 0\n",
    "    else:\n",
    "        count += 1\n",
    "        if count > increase_count:\n",
    "            model.load_state_dict(bestWeight)\n",
    "            break\n",
    "    train_loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbc40d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'micro:0.48531139835487663, macro:0.4075957051873604'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = model(M,A,D,adj_m2d,adj_m2a,adj_d2m,adj_a2m)\n",
    "yhat = yhat.detach().cpu().numpy().argmax(1)\n",
    "\n",
    "'micro:{}, macro:{}'.format(f1_score(y.numpy()[val_idx],yhat[val_idx],average='micro'),\n",
    "                            f1_score(y.numpy()[val_idx],yhat[val_idx],average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a97dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00020b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bf43f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
